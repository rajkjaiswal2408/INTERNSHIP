{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a112c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\stuti\\anaconda2\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb455b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import re \n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df4d78be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\stuti\\anaconda2\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: outcome in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio~=0.17->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\stuti\\anaconda2\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "# Let's import all required libraries\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc06cd",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb340c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750c8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d3ce4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "\n",
    "len(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6305d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "    \n",
    "len(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a5dcfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping Artist\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "len(Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18da046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append('-')\n",
    "\n",
    "len(UploadDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6d3ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Views of videos\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\") \n",
    "len(Views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17209150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>1,000,000</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>255,000</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"[42]</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>1</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"[44]</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[47]</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"[48]</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[53]</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name         Artist  \\\n",
       "1    1.                            \"Baby Shark Dance\"[6]  7,046,700,000   \n",
       "2    2.                                   \"Despacito\"[9]  2,993,700,000   \n",
       "3    3.                       \"Johny Johny Yes Papa\"[16]  2,894,000,000   \n",
       "4    4.                                  \"Bath Song\"[17]    803,700,000   \n",
       "5    5.                               \"Shape of You\"[18]    245,400,000   \n",
       "6    6.                              \"See You Again\"[21]    178,400,000   \n",
       "7    8.                          \"Wheels on the Bus\"[26]    128,900,000   \n",
       "8    7.                \"Phonics Song with Two Words\"[27]    118,900,000   \n",
       "9    9.                                \"Uptown Funk\"[28]     92,600,000   \n",
       "10  10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]     78,400,000   \n",
       "11  11.                              \"Gangnam Style\"[30]     76,600,000   \n",
       "12  12.   \"Masha and the Bear – Recipe for Disaster\"[35]     10,600,000   \n",
       "13  13.                             \"Dame Tu Cosita\"[36]      4,300,000   \n",
       "14  14.                                     \"Axel F\"[37]      2,700,000   \n",
       "15  15.                                      \"Sugar\"[38]      3,400,000   \n",
       "16  16.                                       \"Roar\"[39]      2,300,000   \n",
       "17  17.                             \"Counting Stars\"[40]      1,000,000   \n",
       "18  18.                        \"Baa Baa Black Sheep\"[41]        255,000   \n",
       "19  19.                                      \"Sorry\"[42]        247,000   \n",
       "20  20.           \"Waka Waka (This Time for Africa)\"[43]              1   \n",
       "21  21.                          \"Thinking Out Loud\"[44]  7,046,700,000   \n",
       "22  22.                             \"Lakdi Ki Kathi\"[45]  2,993,700,000   \n",
       "23  23.                                 \"Dark Horse\"[46]  2,894,000,000   \n",
       "24  24.                                    \"Perfect\"[47]    803,700,000   \n",
       "25  25.                                      \"Faded\"[48]    245,400,000   \n",
       "26  26.                                 \"Let Her Go\"[49]    178,400,000   \n",
       "27  27.          \"Humpty the train on a fruits ride\"[50]    128,900,000   \n",
       "28  28.                             \"Girls Like You\"[51]    118,900,000   \n",
       "29  29.                                   \"Bailando\"[52]     92,600,000   \n",
       "30  30.                                    \"Lean On\"[53]     78,400,000   \n",
       "\n",
       "          Upload Date  Views  \n",
       "1       June 17, 2016  13.18  \n",
       "2    January 12, 2017   8.23  \n",
       "3     October 8, 2016   6.76  \n",
       "4         May 2, 2018   6.33  \n",
       "5    January 30, 2017   6.05  \n",
       "6       April 6, 2015   5.98  \n",
       "7        May 24, 2018   5.46  \n",
       "8       March 6, 2014   5.42  \n",
       "9   November 19, 2014   4.99  \n",
       "10  February 27, 2018   4.94  \n",
       "11      July 15, 2012   4.86  \n",
       "12   January 31, 2012   4.55  \n",
       "13      April 5, 2018   4.41  \n",
       "14      June 16, 2009   4.00  \n",
       "15   January 14, 2015   3.91  \n",
       "16  September 5, 2013   3.84  \n",
       "17       May 31, 2013   3.84  \n",
       "18      June 25, 2018   3.73  \n",
       "19   October 22, 2015   3.69  \n",
       "20       June 4, 2010   3.68  \n",
       "21    October 7, 2014   3.63  \n",
       "22      June 14, 2018   3.63  \n",
       "23  February 20, 2014   3.56  \n",
       "24   November 9, 2017   3.51  \n",
       "25   December 3, 2015   3.49  \n",
       "26      July 25, 2012   3.48  \n",
       "27   January 26, 2018   3.51  \n",
       "28       May 31, 2018   3.45  \n",
       "29     April 11, 2014   3.43  \n",
       "30     March 22, 2015   3.43  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "wikipedia = pd.DataFrame({})\n",
    "wikipedia['Rank']=Rank[:30]\n",
    "wikipedia['Name']=Name[:30]\n",
    "wikipedia['Artist']=Artist[:30]\n",
    "wikipedia['Upload Date']=UploadDate[:30]\n",
    "wikipedia['Views']=Views[:30]\n",
    "\n",
    "wikipedia.index +=1\n",
    "wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17781234",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1 ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7d30ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35eb319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on International tab\n",
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8803d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9fdc64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4th T20I ', '5th T20I ', '1st T20I ', '2nd T20I ', '3rd T20I ', '1st ODI ', '2nd ODI ', '1st ODI ']\n"
     ]
    }
   ],
   "source": [
    "#Scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        Match_title.append(i.text.replace('-',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Match_title.append('-')\n",
    "    \n",
    "print(Match_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a512125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF WEST INDIES 2023', 'INDIA TOUR OF IRELAND 2023', 'INDIA TOUR OF IRELAND 2023', 'INDIA TOUR OF IRELAND 2023', 'ASIA CUP 2023', 'ASIA CUP 2023', 'AUSTRALIA TOUR OF INDIA 2023-24']\n"
     ]
    }
   ],
   "source": [
    "#Scrapping Series\n",
    "try:\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')\n",
    "    \n",
    "print(Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2742d729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ 10.3 ov',\n",
       " 'Central Broward Regional Park Stadium Turf Ground',\n",
       " 'Central Broward Regional Park Stadium Turf Ground',\n",
       " 'The Village',\n",
       " 'The Village',\n",
       " 'The Village',\n",
       " 'Pallekele International Cricket Stadium',\n",
       " 'Pallekele International Cricket Stadium',\n",
       " 'Punjab Cricket Association IS Bindra Stadium']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping Place\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        Place.append(i.text.replace(',',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')\n",
    "    \n",
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4bdab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 AUG 2023', '13 AUG 2023', '18 AUG 2023', '20 AUG 2023', '23 AUG 2023', '2 SEP 2023', '4 SEP 2023', '22 SEP 2023']\n"
     ]
    }
   ],
   "source": [
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "\n",
    "print(Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e50270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8:00 PM ', '8:00 PM ', '7:30 PM ', '7:30 PM ', '7:30 PM ', '10:00 AM ', '10:00 AM ', '1:30 PM ']\n"
     ]
    }
   ],
   "source": [
    "#Scrapping Time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "        Time.append(i.text.replace('IST',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')\n",
    "\n",
    "print(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ec5bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 9 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c19f75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Ground</td>\n",
       "      <td>12 AUG 2023</td>\n",
       "      <td>8:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Ground</td>\n",
       "      <td>13 AUG 2023</td>\n",
       "      <td>8:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village</td>\n",
       "      <td>18 AUG 2023</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village</td>\n",
       "      <td>20 AUG 2023</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village</td>\n",
       "      <td>23 AUG 2023</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                           Series  \\\n",
       "1   4th T20I    INDIA TOUR OF WEST INDIES 2023   \n",
       "2   5th T20I    INDIA TOUR OF WEST INDIES 2023   \n",
       "3   1st T20I        INDIA TOUR OF IRELAND 2023   \n",
       "4   2nd T20I        INDIA TOUR OF IRELAND 2023   \n",
       "5   3rd T20I        INDIA TOUR OF IRELAND 2023   \n",
       "6    1st ODI                     ASIA CUP 2023   \n",
       "7    2nd ODI                     ASIA CUP 2023   \n",
       "8    1st ODI   AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                               Place         Date       Time  \n",
       "1  Central Broward Regional Park Stadium Turf Ground  12 AUG 2023   8:00 PM   \n",
       "2  Central Broward Regional Park Stadium Turf Ground  13 AUG 2023   8:00 PM   \n",
       "3                                        The Village  18 AUG 2023   7:30 PM   \n",
       "4                                        The Village  20 AUG 2023   7:30 PM   \n",
       "5                                        The Village  23 AUG 2023   7:30 PM   \n",
       "6            Pallekele International Cricket Stadium   2 SEP 2023  10:00 AM   \n",
       "7            Pallekele International Cricket Stadium   4 SEP 2023  10:00 AM   \n",
       "8       Punjab Cricket Association IS Bindra Stadium  22 SEP 2023   1:30 PM   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "BCCI_FIXTURES = pd.DataFrame({})\n",
    "BCCI_FIXTURES['Match_Title']=Match_title\n",
    "BCCI_FIXTURES['Series']=Series\n",
    "BCCI_FIXTURES['Place']=Place[1:9]\n",
    "BCCI_FIXTURES['Date']=Date\n",
    "BCCI_FIXTURES['Time']=Time\n",
    "\n",
    "BCCI_FIXTURES.index +=1\n",
    "BCCI_FIXTURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f27ca7",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cdb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f4fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on Economy page tab\n",
    "Economy= driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button/i') # click button\n",
    "Economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40875c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on INDIA tab in dropdown\n",
    "India= driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click() # click button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4955edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the GDPofIndianStates\n",
    "GDP=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0c56613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b22b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33']\n"
     ]
    }
   ],
   "source": [
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "print(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a7f0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Karnataka',\n",
       " 'Gujarat',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Telangana',\n",
       " 'Andhra Pradesh',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Jharkhand',\n",
       " 'Chhattisgarh',\n",
       " 'Uttarakhand',\n",
       " 'Himachal Pradesh',\n",
       " 'Jammu & Kashmir',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Manipur',\n",
       " 'Sikkim',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacb1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd08d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175d1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc1f30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d578a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP1</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDPbillion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE      GSDP1      GSDP2   SHARE GDPbillion\n",
       "1     1                Maharashtra          -  2,632,792  13.94%    399.921\n",
       "2     2                 Tamil Nadu  1,845,853  1,630,208   8.63%    247.629\n",
       "3     3              Uttar Pradesh  1,687,818  1,584,764   8.39%    240.726\n",
       "4     4                    Gujarat          -  1,502,899   7.96%    228.290\n",
       "5     5                  Karnataka  1,631,977  1,493,127   7.91%    226.806\n",
       "6     6                West Bengal  1,253,832  1,089,898   5.77%    165.556\n",
       "7     7                  Rajasthan  1,020,989    942,586   4.99%    143.179\n",
       "8     8             Andhra Pradesh    972,782    862,957   4.57%    131.083\n",
       "9     9                  Telangana    969,604    861,031   4.56%    130.791\n",
       "10   10             Madhya Pradesh    906,672    809,592   4.29%    122.977\n",
       "11   11                     Kerala          -    781,653   4.14%    118.733\n",
       "12   12                      Delhi    856,112    774,870   4.10%    117.703\n",
       "13   13                    Haryana    831,610    734,163   3.89%    111.519\n",
       "14   14                      Bihar    611,804    530,363   2.81%     80.562\n",
       "15   15                     Punjab    574,760    526,376   2.79%     79.957\n",
       "16   16                     Odisha    521,275    487,805   2.58%     74.098\n",
       "17   17                      Assam          -    315,881   1.67%     47.982\n",
       "18   18               Chhattisgarh    329,180    304,063   1.61%     46.187\n",
       "19   19                  Jharkhand    328,598    297,204   1.57%     45.145\n",
       "20   20                Uttarakhand          -    245,895   1.30%     37.351\n",
       "21   21            Jammu & Kashmir          -    155,956   0.83%     23.690\n",
       "22   22           Himachal Pradesh    165,472    153,845   0.81%     23.369\n",
       "23   23                        Goa     80,449     73,170   0.39%     11.115\n",
       "24   24                    Tripura     55,984     49,845   0.26%      7.571\n",
       "25   25                 Chandigarh          -     42,114   0.22%      6.397\n",
       "26   26                 Puducherry     38,253     34,433   0.18%      5.230\n",
       "27   27                  Meghalaya     36,572     33,481   0.18%      5.086\n",
       "28   28                     Sikkim     32,496     28,723   0.15%      4.363\n",
       "29   29                    Manipur     31,790     27,870   0.15%      4.233\n",
       "30   30                   Nagaland          -     27,283   0.14%      4.144\n",
       "31   31          Arunachal Pradesh          -     24,603   0.13%      3.737\n",
       "32   32                    Mizoram     26,503     22,287   0.12%      3.385\n",
       "33   33  Andaman & Nicobar Islands          -          -       -          -"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDIA=pd.DataFrame()\n",
    "INDIA['RANK']=Rank[:33]\n",
    "INDIA['STATE']=State[:33]\n",
    "INDIA['GSDP1']=GSDP1[:33]\n",
    "INDIA['GSDP2']=GSDP2[:33]\n",
    "INDIA['SHARE']=Share[:33]\n",
    "INDIA['GDPbillion']=GDPbillion[:33]\n",
    "INDIA.index +=1\n",
    "INDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4047a47",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34b1866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \" https://github.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a624b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the Open Source (More Dropdown) \n",
    "Open_Source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aff1814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clckiing Trending Tab\n",
    "Trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1e0bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list:\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d3715f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['huggingface', 'clockworklabs', 'TheAlgorithms', 'radix-ui', 'joonspk-research', 'PeiQi0', 'morph-labs', 'hackclub', 'kognise', 'remote-es', 'wangdoc', 'blakeblackshear', 't3dotgg', 'vllm-project', 'dvlab-research', 'THUDM', 'axios', 'aquasecurity', 'taikoxyz', 'orkestral', 'practical-tutorials', 'supabase', 'microsoft', 'jwasham', 'nlohmann']\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository Title\n",
    "title=[]\n",
    "try:\n",
    "    titles=driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "    for x in titles:\n",
    "        title.append(x.text.replace(' /',''))\n",
    "except NoSuchElementException:\n",
    "    title.append('-')\n",
    "    \n",
    "print(len(title),title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05d7c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['Minimalist ML framework for Rust', 'Multiplayer at the speed of light', 'All Algorithms implemented in Python', 'Radix Themes is an open-source component library optimized for fast development, easy maintenance, and accessibility. Maintained by @workos.', 'Generative Agents: Interactive Simulacra of Human Behavior', '面向网络安全从业者的知识文库🍃', 'Rift: an AI-native language server for your personal AI software engineer', 'A technical explainer by @kognise of how your computer runs programs, from start to finish.', 'Answering the question nobody asked: what if you wanted to text your friends using only ARP?', 'This is a repository listing companies which offer full-time remote jobs with Spanish contracts', 'TypeScript 教程', 'NVR with realtime local object detection for IP cameras', 'poorly guess how much money a tweet is worth', 'A high-throughput and memory-efficient inference and serving engine for LLMs', 'Project Page for \"LISA: Reasoning Segmentation via Large Language Model\"', 'A Comprehensive Benchmark to Evaluate LLMs as Agents', 'Promise based HTTP client for the browser and node.js', 'Cloud Security Posture Management (CSPM)', 'A decentralized, Ethereum-equivalent ZK-Rollup. 🥁', 'Venom is the most complete javascript library for Whatsapp, 100% Open Source.', 'Curated list of project-based tutorials', 'The open source Firebase alternative. Follow to stay updated about our public Beta.', '24 Lessons, 12 Weeks, Get Started as a Web Developer', 'A complete computer science study plan to become a software engineer.', 'JSON for Modern C++']\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository Description\n",
    "try:\n",
    "    description=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for x in description:\n",
    "        Description.append(x.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('-')\n",
    "    \n",
    "print(len(Description),Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "850df6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['173', '29', '41,148', '27', '602', '434', '59', '54', '44', '154', '80', '937', '30', '489', '35', '24', '10,454', '622', '784', '912', '15,867', '4,325', '11,617', '68,943', '6,189']\n"
     ]
    }
   ],
   "source": [
    "#Scrape Repository Title\n",
    "Contributors=[]\n",
    "try:\n",
    "    contributors=driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "    for x in contributors:\n",
    "        Contributors.append(x.text.replace(' /',''))\n",
    "except NoSuchElementException:\n",
    "    Contributors.append('-')\n",
    "\n",
    "Contributors = Contributors[1::2]\n",
    "print(len(Contributors),Contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2df68636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ['Rust', 'Rust', 'Python', 'TypeScript', 'Python', 'MDX', 'Rust', 'Python', 'JavaScript', 'Python', 'Python', 'C++', 'JavaScript', 'JavaScript', 'HTML', 'JavaScript', 'TypeScript', 'JavaScript', 'C++']\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store the extracted languages\n",
    "Language = []\n",
    "\n",
    "try:\n",
    "    # Find the elements that contain the language information using XPath\n",
    "    language_elements = driver.find_elements(By.XPATH, '//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "\n",
    "    for x in language_elements:\n",
    "        try:\n",
    "            Language.append(x.text.replace(' /', ''))\n",
    "        except:\n",
    "            # Handle the case when language information extraction fails\n",
    "            Language.append('-')\n",
    "\n",
    "except NoSuchElementException:\n",
    "    # Handle the case when the language elements are not found on the page\n",
    "    Language.append('-')\n",
    "\n",
    "# Print the number of languages found and the list of languages\n",
    "print(len(Language), Language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a87a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Repository Contributors</th>\n",
       "      <th>Repository Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huggingface</td>\n",
       "      <td>Minimalist ML framework for Rust</td>\n",
       "      <td>173</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clockworklabs</td>\n",
       "      <td>Multiplayer at the speed of light</td>\n",
       "      <td>29</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheAlgorithms</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>41,148</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radix-ui</td>\n",
       "      <td>Radix Themes is an open-source component libra...</td>\n",
       "      <td>27</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joonspk-research</td>\n",
       "      <td>Generative Agents: Interactive Simulacra of Hu...</td>\n",
       "      <td>602</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PeiQi0</td>\n",
       "      <td>面向网络安全从业者的知识文库🍃</td>\n",
       "      <td>434</td>\n",
       "      <td>MDX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>morph-labs</td>\n",
       "      <td>Rift: an AI-native language server for your pe...</td>\n",
       "      <td>59</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hackclub</td>\n",
       "      <td>A technical explainer by @kognise of how your ...</td>\n",
       "      <td>54</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kognise</td>\n",
       "      <td>Answering the question nobody asked: what if y...</td>\n",
       "      <td>44</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>remote-es</td>\n",
       "      <td>This is a repository listing companies which o...</td>\n",
       "      <td>154</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wangdoc</td>\n",
       "      <td>TypeScript 教程</td>\n",
       "      <td>80</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>blakeblackshear</td>\n",
       "      <td>NVR with realtime local object detection for I...</td>\n",
       "      <td>937</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t3dotgg</td>\n",
       "      <td>poorly guess how much money a tweet is worth</td>\n",
       "      <td>30</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vllm-project</td>\n",
       "      <td>A high-throughput and memory-efficient inferen...</td>\n",
       "      <td>489</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dvlab-research</td>\n",
       "      <td>Project Page for \"LISA: Reasoning Segmentation...</td>\n",
       "      <td>35</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THUDM</td>\n",
       "      <td>A Comprehensive Benchmark to Evaluate LLMs as ...</td>\n",
       "      <td>24</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>axios</td>\n",
       "      <td>Promise based HTTP client for the browser and ...</td>\n",
       "      <td>10,454</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aquasecurity</td>\n",
       "      <td>Cloud Security Posture Management (CSPM)</td>\n",
       "      <td>622</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>taikoxyz</td>\n",
       "      <td>A decentralized, Ethereum-equivalent ZK-Rollup. 🥁</td>\n",
       "      <td>784</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Repository title                             Repository description  \\\n",
       "0        huggingface                   Minimalist ML framework for Rust   \n",
       "1      clockworklabs                  Multiplayer at the speed of light   \n",
       "2      TheAlgorithms               All Algorithms implemented in Python   \n",
       "3           radix-ui  Radix Themes is an open-source component libra...   \n",
       "4   joonspk-research  Generative Agents: Interactive Simulacra of Hu...   \n",
       "5             PeiQi0                                    面向网络安全从业者的知识文库🍃   \n",
       "6         morph-labs  Rift: an AI-native language server for your pe...   \n",
       "7           hackclub  A technical explainer by @kognise of how your ...   \n",
       "8            kognise  Answering the question nobody asked: what if y...   \n",
       "9          remote-es  This is a repository listing companies which o...   \n",
       "10           wangdoc                                      TypeScript 教程   \n",
       "11   blakeblackshear  NVR with realtime local object detection for I...   \n",
       "12           t3dotgg       poorly guess how much money a tweet is worth   \n",
       "13      vllm-project  A high-throughput and memory-efficient inferen...   \n",
       "14    dvlab-research  Project Page for \"LISA: Reasoning Segmentation...   \n",
       "15             THUDM  A Comprehensive Benchmark to Evaluate LLMs as ...   \n",
       "16             axios  Promise based HTTP client for the browser and ...   \n",
       "17      aquasecurity           Cloud Security Posture Management (CSPM)   \n",
       "18          taikoxyz  A decentralized, Ethereum-equivalent ZK-Rollup. 🥁   \n",
       "\n",
       "   Repository Contributors Repository Language  \n",
       "0                      173                Rust  \n",
       "1                       29                Rust  \n",
       "2                   41,148              Python  \n",
       "3                       27          TypeScript  \n",
       "4                      602              Python  \n",
       "5                      434                 MDX  \n",
       "6                       59                Rust  \n",
       "7                       54              Python  \n",
       "8                       44          JavaScript  \n",
       "9                      154              Python  \n",
       "10                      80              Python  \n",
       "11                     937                 C++  \n",
       "12                      30          JavaScript  \n",
       "13                     489          JavaScript  \n",
       "14                      35                HTML  \n",
       "15                      24          JavaScript  \n",
       "16                  10,454          TypeScript  \n",
       "17                     622          JavaScript  \n",
       "18                     784                 C++  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = title[:19]\n",
    "Github['Repository description'] = Description[:19]\n",
    "Github['Repository Contributors'] = Contributors[:19]\n",
    "Github['Repository Language'] = Language[:19]\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6dfc30",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "390fc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33c44569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on cHART tab\n",
    "hot=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f8e678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on HOT100 tab\n",
    "hot100=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ae3783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Last Night', 'Fast Car', 'Meltdown', 'Cruel Summer', 'FE!N', 'Calm Down', 'Fukumean', 'Barbie World', 'Vampire', 'Dance The Night', 'I Know ?', 'Flowers', 'All My Life', 'Hyaena', 'Snooze', 'Thank God', 'Topia Twins', 'K-POP', 'My Eyes', 'Karma', 'Try That In A Small Town', 'What Was I Made For?', 'Modern Jam', 'Need A Favor', 'Delresto (Echoes)', 'Telekinesis', 'Sirens', \"God's Country\", 'Kill Bill', 'Seven', 'Anti-Hero', \"Creepin'\", 'Religiously', 'Skitzo', 'Chemical', 'Circus Maximus', \"Thinkin' Bout Me\", 'Til Further Notice', 'Favorite Song', 'Mourning', 'Cupid', 'Ella Baila Sola', 'In Your Love', 'Dial Drunk', 'Next Thing You Know', 'Lost Forever', 'You, Me, & Whiskey', 'Love You Anyway', 'Looove', 'Thought You Should Know', 'Bury Me In Georgia', 'La Bebe', 'Parasail', 'Search & Rescue', 'Jealousy', 'Enough Is Enough', 'Put It On Da Floor Again', 'Deli', 'Un x100to', 'LaLa', 'Where She Goes', 'Princess Diana', 'Lady Gaga', \"Baby Don't Hurt Me\", 'Area Codes', 'What It Is (Block Boy)', 'Something Real', 'Overdrive', 'Peaches & Eggplants', 'Sabor Fresa', 'Watermelon Moonshine', 'Your Heart Or Mine', 'Eyes Closed', 'Daylight', 'Tulum', \"I Can See You (Taylor's Version) (From The Vault)\", 'Super Shy', 'Speed Drive', 'White Horse', 'On The Radar Freestyle', 'Stand By Me', 'Fragil', 'Everything I Love', 'Shake Sumn', 'TQM', 'Popular', 'Too Cool To Die', \"Don't Understand\", 'Aqui Te Espero', 'Novacandy', 'Truck Bed', \"I'm Just Ken\", 'Jaded', 'Heartbroken', 'Memory Lane', 'Oh U Went', 'ICU', 'Pound Town 2', 'Bzrp Music Sessions, Vol. 55', 'Johnny Dang']\n"
     ]
    }
   ],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "# Scraping name\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "    Song_Name.append(i.text.split('\\n')[0])\n",
    "print(len(Song_Name),Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c82ca71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist_Name=[]\n",
    "#Scrappin Artist name 1 st one\n",
    "Artist_Name.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)\n",
    "\n",
    "#Remainig Artist Name\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist_Name.extend([i.text for i in artistTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "634ab646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Morgan Wallen', 'Luke Combs', 'Travis Scott Featuring Drake', 'Taylor Swift', 'Travis Scott Featuring Playboi Carti', 'Rema & Selena Gomez', 'Gunna', 'Nicki Minaj & Ice Spice With Aqua', 'Olivia Rodrigo', 'Dua Lipa', 'Travis Scott', 'Miley Cyrus', 'Lil Durk Featuring J. Cole', 'Travis Scott', 'SZA', 'Travis Scott', 'Travis Scott Featuring Rob49 & 21 Savage', 'Travis Scott, Bad Bunny & The Weeknd', 'Travis Scott', 'Taylor Swift Featuring Ice Spice', 'Jason Aldean', 'Billie Eilish', 'Travis Scott Featuring Teezo Touchdown', 'Jelly Roll', 'Travis Scott & Beyonce', 'Travis Scott Featuring SZA & Future', 'Travis Scott', 'Travis Scott', 'SZA', 'Jung Kook Featuring Latto', 'Taylor Swift', 'Metro Boomin, The Weeknd & 21 Savage', 'Bailey Zimmerman', 'Travis Scott Featuring Young Thug', 'Post Malone', 'Travis Scott Featuring The Weeknd & Swae Lee', 'Morgan Wallen', 'Travis Scott Featuring James Blake & 21 Savage', 'Toosii', 'Post Malone', 'Fifty Fifty', 'Eslabon Armado X Peso Pluma', 'Tyler Childers', 'Noah Kahan With Post Malone', 'Jordan Davis', 'Travis Scott Featuring Westside Gunn', 'Justin Moore & Priscilla Block', 'Luke Combs', 'Travis Scott Featuring Kid Cudi', 'Morgan Wallen', 'Kane Brown', 'Yng Lvcas x Peso Pluma', 'Travis Scott Featuring Yung Lean & Dave Chappelle', 'Drake', 'Offset & Cardi B', 'Post Malone', 'Latto Featuring Cardi B', 'Ice Spice', 'Grupo Frontera X Bad Bunny', 'Myke Towers', 'Bad Bunny', 'Ice Spice & Nicki Minaj', 'Peso Pluma, Gabito Ballesteros & Junior H', 'David Guetta, Anne-Marie & Coi Leray', 'Kaliii', 'Doechii Featuring Kodak Black', 'Post Malone', 'Post Malone', 'Young Nudy Featuring 21 Savage', 'Fuerza Regida', 'Lainey Wilson', 'Jon Pardi', 'Ed Sheeran', 'David Kushner', 'Peso Pluma & Grupo Frontera', 'Taylor Swift', 'NewJeans', 'Charli XCX', 'Chris Stapleton', 'Drake & Central Cee', 'Lil Durk Featuring Morgan Wallen', 'Yahritza y Su Esencia x Grupo Frontera', 'Morgan Wallen', 'DaBaby', 'Fuerza Regida', 'The Weeknd, Playboi Carti & Madonna', 'Post Malone', 'Post Malone', 'Ivan Cornejo', 'Post Malone', 'HARDY', 'Ryan Gosling', 'Miley Cyrus', 'Diplo, Jessie Murph & Polo G', 'Old Dominion', 'Young Thug Featuring Drake', 'Coco Jones', 'Sexyy Red & Tay Keith & Nicki Minaj', 'Bizarrap & Peso Pluma', 'That Mexican OT, Paul Wall & DRODi']\n"
     ]
    }
   ],
   "source": [
    "print(len(Artist_Name),Artist_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f916527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594 ['3', '2', '19', '', '', '', '-', '3', '1', '', '', '', '6', '4', '13', '', '', '', '-', '5', '1', '', '', '', '5', '3', '48', '', '', '', '4', '4', '7', '', '', '', '8', '7', '6', '', '', '', '10', '1', '5', '', '', '', '12', '10', '10', '', '', '', '-', '11', '1', '', '', '', '11', '1', '29', '', '', '', '13', '2', '12', '', '', '', '-', '14', '1', '', '', '', '14', '11', '34', '', '', '', '-', '16', '1', '', '', '', '-', '17', '1', '', '', '', '7', '7', '2', '', '', '', '-', '19', '1', '', '', '', '15', '2', '21', '', '', '', '1', '1', '3', '', '', '', '18', '18', '3', '', '', '', '-', '23', '1', '', '', '', '16', '14', '18', '', '', '', '-', '25', '1', '', '', '', '-', '26', '1', '', '', '', '-', '27', '1', '', '', '', '-', '28', '1', '', '', '', '17', '1', '34', '', '', '', '9', '1', '3', '', '', '', '22', '1', '41', '', '', '', '20', '3', '35', '', '', '', '24', '24', '13', '', '', '', '-', '34', '1', '', '', '', '46', '13', '16', '', '', '', '-', '36', '1', '', '', '', '27', '9', '22', '', '', '', '-', '38', '1', '', '', '', '23', '5', '24', '', '', '', '60', '36', '11', '', '', '', '29', '17', '20', '', '', '', '28', '4', '20', '', '', '', '-', '43', '1', '', '', '', '25', '25', '7', '', '', '', '30', '23', '28', '', '', '', '-', '46', '1', '', '', '', '52', '47', '13', '', '', '', '37', '15', '25', '', '', '', '-', '49', '1', '', '', '', '34', '7', '51', '', '', '', '39', '39', '12', '', '', '', '32', '11', '20', '', '', '', '-', '53', '1', '', '', '', '35', '2', '17', '', '', '', '-', '55', '1', '', '', '', '-', '56', '1', '', '', '', '42', '13', '9', '', '', '', '41', '41', '2', '', '', '', '36', '5', '16', '', '', '', '49', '48', '4', '', '', '', '43', '8', '11', '', '', '', '40', '4', '16', '', '', '', '51', '35', '6', '', '', '', '55', '55', '11', '', '', '', '53', '33', '13', '', '', '', '58', '54', '13', '', '', '', '-', '67', '1', '', '', '', '-', '47', '2', '', '', '', '57', '52', '9', '', '', '', '50', '26', '6', '', '', '', '61', '60', '6', '', '', '', '54', '53', '12', '', '', '', '44', '19', '19', '', '', '', '59', '47', '16', '', '', '', '56', '43', '5', '', '', '', '45', '5', '4', '', '', '', '48', '48', '4', '', '', '', '73', '73', '2', '', '', '', '31', '31', '2', '', '', '', '-', '80', '1', '', '', '', '62', '22', '10', '', '', '', '70', '69', '15', '', '', '', '67', '14', '23', '', '', '', '65', '65', '11', '', '', '', '63', '34', '11', '', '', '', '68', '43', '9', '', '', '', '-', '87', '1', '', '', '', '-', '88', '1', '', '', '', '-', '89', '1', '', '', '', '-', '90', '1', '', '', '', '69', '69', '7', '', '', '', '87', '87', '2', '', '', '', '78', '56', '11', '', '', '', '64', '64', '2', '', '', '', '47', '27', '18', '', '', '', '66', '19', '6', '', '', '', '71', '62', '18', '', '', '', '74', '66', '9', '', '', '', '72', '31', '9', '', '', '', '96', '96', '3', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "#Scapping Rank\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])\n",
    "\n",
    "#Remaining RAnk\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2b176e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c14ac9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03d10bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 133, 133, 133)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Song_Name),len(Artist_Name),len(lastweekpos),len(peakPos),len(weeksonBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8783992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meltdown</td>\n",
       "      <td>Travis Scott Featuring Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FE!N</td>\n",
       "      <td>Travis Scott Featuring Playboi Carti</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Oh U Went</td>\n",
       "      <td>Young Thug Featuring Drake</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ICU</td>\n",
       "      <td>Coco Jones</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pound Town 2</td>\n",
       "      <td>Sexyy Red &amp; Tay Keith &amp; Nicki Minaj</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Johnny Dang</td>\n",
       "      <td>That Mexican OT, Paul Wall &amp; DRODi</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        SongName                            ArtistName  \\\n",
       "0                     Last Night                         Morgan Wallen   \n",
       "1                       Fast Car                            Luke Combs   \n",
       "2                       Meltdown          Travis Scott Featuring Drake   \n",
       "3                   Cruel Summer                          Taylor Swift   \n",
       "4                           FE!N  Travis Scott Featuring Playboi Carti   \n",
       "..                           ...                                   ...   \n",
       "95                     Oh U Went            Young Thug Featuring Drake   \n",
       "96                           ICU                            Coco Jones   \n",
       "97                  Pound Town 2   Sexyy Red & Tay Keith & Nicki Minaj   \n",
       "98  Bzrp Music Sessions, Vol. 55                 Bizarrap & Peso Pluma   \n",
       "99                   Johnny Dang    That Mexican OT, Paul Wall & DRODi   \n",
       "\n",
       "   Last Week PeekPosition Weeks On board  \n",
       "0          2            1             27  \n",
       "1          3            2             19  \n",
       "2          -            3              1  \n",
       "3          6            4             13  \n",
       "4          -            5              1  \n",
       "..       ...          ...            ...  \n",
       "95        70           69             15  \n",
       "96                                        \n",
       "97        67           14             23  \n",
       "98                                        \n",
       "99        65           65             11  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Song_Name[0:100]\n",
    "df['ArtistName']=Artist_Name\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512e8c1",
   "metadata": {},
   "source": [
    "# Url =\n",
    "https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-You have to find the following details:\n",
    "    \n",
    "6. Scrape the details of Highest selling novels.\n",
    "compare\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1b20a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a416f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d4b004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f70074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Bookname),len(Authorname),len(Volumessold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67f932bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Book Name            Author  \\\n",
       "1                                    Da Vinci Code,The        Brown, Dan   \n",
       "2                 Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3             Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4            Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                 Fifty Shades of Grey      James, E. L.   \n",
       "..                                                 ...               ...   \n",
       "96                                           Ghost,The    Harris, Robert   \n",
       "97                      Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98               Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99   Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "    Volume sold        Publisher                        Genre  \n",
       "1     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2     4,475,152       Bloomsbury           Children's Fiction  \n",
       "3     4,200,654       Bloomsbury           Children's Fiction  \n",
       "4     4,179,479       Bloomsbury           Children's Fiction  \n",
       "5     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "96      807,311     Random House   General & Literary Fiction  \n",
       "97      794,201          Penguin        Food & Drink: General  \n",
       "98      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99      791,507            Orion           Biography: General  \n",
       "100     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels.index +=1\n",
    "Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c5865",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da997206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \" https://www.imdb.com/list/ls095964455/ \"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67c9eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd99a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1e8ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_span),len(Run_time),len(Ratings),len(Genre),len(Votes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be086268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,191,293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,265,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>209,934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,191,293  \n",
       "1    51 min     8.7  1,265,377  \n",
       "2    44 min     8.1  1,040,213  \n",
       "3    60 min     7.5    305,737  \n",
       "4    43 min     7.6    264,804  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,380  \n",
       "96   50 min     7.8     64,405  \n",
       "97   42 min     8.1    209,934  \n",
       "98   45 min       7     43,649  \n",
       "99  572 min     8.6    263,289  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series=pd.DataFrame({})\n",
    "series['Name'] = Name\n",
    "series['Year Span'] = Year_span\n",
    "series['Genre'] = Genre\n",
    "series['Run Time'] = Run_time\n",
    "series['Ratings'] = Ratings\n",
    "series['Votes'] = Votes\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be9cd4",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62063c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47024bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")    \n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b676fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls for each dataset\n",
    "dataset_url = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')    \n",
    "\n",
    "urls = []     \n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09c34389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "190038a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        dataset_name = driver.find_element(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element(By.XPATH,'//p[@class=\"text-md\"]')\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    \n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]//div//p')\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element(By.XPATH,'//p[@class=\"text-md\"]')\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,'//p[@class=\"text-md\"]')\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of attributes\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,'//p[@class=\"text-md\"]')\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,'//h2[@class=\"text-primary-content\"]')\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf113657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Data Name                  Data Type  \\\n",
       "0                                  Iris               Multivariate   \n",
       "1                         Heart Disease               Multivariate   \n",
       "2                                 Adult               Multivariate   \n",
       "3                      Dry Bean Dataset               Multivariate   \n",
       "4                              Diabetes  Multivariate, Time-Series   \n",
       "5                                  Wine               Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "7                        Car Evaluation               Multivariate   \n",
       "8            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "9                              Mushroom               Multivariate   \n",
       "\n",
       "                        Task             Attribute type  \\\n",
       "0               Multivariate               Multivariate   \n",
       "1               Multivariate               Multivariate   \n",
       "2               Multivariate               Multivariate   \n",
       "3               Multivariate               Multivariate   \n",
       "4  Multivariate, Time-Series  Multivariate, Time-Series   \n",
       "5               Multivariate               Multivariate   \n",
       "6               Multivariate               Multivariate   \n",
       "7               Multivariate               Multivariate   \n",
       "8               Multivariate               Multivariate   \n",
       "9               Multivariate               Multivariate   \n",
       "\n",
       "              No of instance           No of attributes  Year  \n",
       "0               Multivariate               Multivariate  Dona  \n",
       "1               Multivariate               Multivariate  Dona  \n",
       "2               Multivariate               Multivariate  Dona  \n",
       "3               Multivariate               Multivariate  Dona  \n",
       "4  Multivariate, Time-Series  Multivariate, Time-Series     -  \n",
       "5               Multivariate               Multivariate  Dona  \n",
       "6               Multivariate               Multivariate  Dona  \n",
       "7               Multivariate               Multivariate  Dona  \n",
       "8               Multivariate               Multivariate  Dona  \n",
       "9               Multivariate               Multivariate  Dona  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe \n",
    "\n",
    "MachineLearning=pd.DataFrame({})\n",
    "MachineLearning['Data Name'] = Dataset_name[:10]\n",
    "MachineLearning['Data Type'] = Data_type[:10]\n",
    "MachineLearning['Task'] = Task[:10]\n",
    "MachineLearning['Attribute type'] = Attribute_type[:10]\n",
    "MachineLearning['No of instance'] = No_of_instances[:10]\n",
    "MachineLearning['No of attributes'] = No_of_attributes[:10]\n",
    "MachineLearning['Year'] = Year[:10]\n",
    "MachineLearning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
